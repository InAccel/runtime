--- inference/vision/classification_and_detection/python/backend_inaccel.py
+++ inference/vision/classification_and_detection/python/backend_inaccel.py
@@ -0,0 +1,41 @@
+"""
+InAccel backend (https://github.com/inaccel/keras)
+"""
+
+# pylint: disable=unused-argument,missing-docstring,useless-super-delegation
+
+from inaccel.keras.applications.imagenet_utils import decode_predictions
+from inaccel.keras.applications.mobilenet import MobileNet
+from inaccel.keras.applications.resnet50 import ResNet50
+
+import backend
+
+class BackendInAccel(backend.Backend):
+    def __init__(self):
+        super(BackendInAccel, self).__init__()
+
+    def version(self):
+        return "keras"
+
+    def name(self):
+        return "inaccel"
+
+    def image_format(self):
+        return "NHWC"
+
+    def load(self, model_path, inputs=None, outputs=None):
+        if not inputs:
+            raise ValueError("BackendInAccel needs inputs")
+        if not outputs:
+            raise ValueError("BackendInAccel needs outputs")
+        self.inputs = inputs
+        self.outputs = outputs
+
+        if self.outputs[0] == "ResNet50":
+            self.model = ResNet50(weights=model_path)
+        elif self.outputs[0] == "MobileNet":
+            self.model = MobileNet()
+        return self
+
+    def predict(self, feed):
+        return [self.model.predict_on_batch(feed[self.inputs[0]])[:, 0]]

--- inference/vision/classification_and_detection/python/dataset.py
+++ inference/vision/classification_and_detection/python/dataset.py
@@ -202,6 +202,18 @@
     return img
 
 
+def pre_process_inaccel(img, dims=None, need_transpose=False):
+    output_height, output_width, _ = dims
+    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
+    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)
+    img = center_crop(img, output_height, output_width)
+
+    # transpose if needed
+    if need_transpose:
+        img = img.transpose([2, 0, 1])
+    return img
+
+
 def maybe_resize(img, dims):
     img = np.array(img, dtype=np.float32)
     if len(img.shape) < 3 or img.shape[2] != 3:

--- inference/vision/classification_and_detection/python/main.py
+++ inference/vision/classification_and_detection/python/main.py
@@ -40,6 +40,9 @@
     "imagenet_mobilenet":
         (imagenet.Imagenet, dataset.pre_process_mobilenet, dataset.PostProcessArgMax(offset=-1),
          {"image_size": [224, 224, 3]}),
+    "imagenet_inaccel":
+        (imagenet.Imagenet, dataset.pre_process_inaccel, dataset.PostProcessCommon(offset=0),
+         {"image_size": [224, 224, 3]}),
     "coco-300":
         (coco.Coco, dataset.pre_process_coco_mobilenet, coco.PostProcessCoco(),
          {"image_size": [300, 300, 3]}),
@@ -85,6 +88,13 @@
         "backend": "onnxruntime",
         "model-name": "resnet50",
     },
+    "resnet50-inaccel": {
+        "inputs": "input",
+        "outputs": "ResNet50",
+        "dataset": "imagenet_inaccel",
+        "backend": "inaccel",
+        "model-name": "resnet50",
+    },
 
     # mobilenet
     "mobilenet-tf": {
@@ -100,6 +110,13 @@
         "backend": "onnxruntime",
         "model-name": "mobilenet",
     },
+    "mobilenet-inaccel": {
+        "inputs": "input",
+        "outputs": "MobileNet",
+        "dataset": "imagenet_inaccel",
+        "backend": "inaccel",
+        "model-name": "mobilenet",
+    },
 
     # ssd-mobilenet
     "ssd-mobilenet-tf": {
@@ -244,6 +261,9 @@
     elif backend == "tflite":
         from backend_tflite import BackendTflite
         backend = BackendTflite()
+    elif backend == "inaccel":
+        from backend_inaccel import BackendInAccel
+        backend = BackendInAccel()
     else:
         raise ValueError("unknown backend: " + backend)
     return backend
@@ -459,9 +479,9 @@
 
     # warmup
     ds.load_query_samples([0])
-    for _ in range(5):
-        img, _ = ds.get_samples([0])
-        _ = backend.predict({backend.inputs[0]: img})
+#    for _ in range(5):
+#        img, _ = ds.get_samples([0])
+#        _ = backend.predict({backend.inputs[0]: img})
     ds.unload_query_samples(None)
 
     scenario = SCENARIO_MAP[args.scenario]
@@ -512,7 +532,7 @@
         settings.multi_stream_samples_per_query = args.samples_per_query
     if args.max_latency:
         settings.server_target_latency_ns = int(args.max_latency * NANO_SEC)
-        settings.multi_stream_target_latency_ns = int(args.max_latency * NANO_SEC)
+        settings.multi_stream_target_latency_ns = int(7 * MILLI_SEC)
 
     sut = lg.ConstructSUT(issue_queries, flush_queries, process_latencies)
     qsl = lg.ConstructQSL(count, min(count, 500), ds.load_query_samples, ds.unload_query_samples)

--- inference/vision/classification_and_detection/run_common.sh
+++ inference/vision/classification_and_detection/run_common.sh
@@ -1,7 +1,7 @@
 #!/bin/bash
 
 if [ $# -lt 1 ]; then
-    echo "usage: $0 tf|onnxruntime|pytorch|tflite [resnet50|mobilenet|ssd-mobilenet|ssd-resnet34] [cpu|gpu]"
+    echo "usage: $0 tf|onnxruntime|pytorch|tflite|inaccel [resnet50|mobilenet|ssd-mobilenet|ssd-resnet34] [cpu|gpu|fpga]"
     exit 1
 fi
 if [ "x$DATA_DIR" == "x" ]; then
@@ -18,8 +18,8 @@
 
 for i in $* ; do
     case $i in
-       tf|onnxruntime|tflite|pytorch) backend=$i; shift;;
-       cpu|gpu) device=$i; shift;;
+       tf|onnxruntime|tflite|pytorch|inaccel) backend=$i; shift;;
+       cpu|gpu|fpga) device=$i; shift;;
        gpu) device=gpu; shift;;
        resnet50|mobilenet|ssd-mobilenet|ssd-resnet34|ssd-resnet34-tf) model=$i; shift;;
     esac
@@ -111,5 +111,17 @@
     extra_args="$extra_args --backend tflite"
 fi
 
+
+#
+# inaccel
+#
+if [ $name == "resnet50-inaccel" ] ; then
+    model_path="$MODEL_DIR/resnet50_weights.h5"
+    profile=resnet50-inaccel
+elif [ $name == "mobilenet-inaccel" ] ; then
+    model_path="-"
+    profile=mobilenet-inaccel
+fi
+
 name="$backend-$device/$model"
 EXTRA_OPS="$extra_args $EXTRA_OPS"
